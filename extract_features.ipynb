{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "#Generates the features\n",
    "# Define paths\n",
    "path_LT_Pulses_Flag = ... #Origin folder of LT HP Pulses Flag as generated from generate_power_data_for_LT_ASHP.ipynb\n",
    "path_LT_Sparsity = ... #Destination folder for LT ASHP Sparsity data\n",
    "path_LT_Pulses = ... #Destination folder for LT ASHP Pulses data\n",
    "\n",
    "# Load dataset the path where the modified all_summary.csv file is located \n",
    "all_summary = pd.read_csv('all_summary.csv')  \n",
    "\n",
    "# Filter data\n",
    "all_summary = all_summary[all_summary['Included_SPF_analysis'] == True]\n",
    "all_summary_LT_ASHP = all_summary[all_summary['HP_Installed'] == \"ASHP\"]\n",
    "\n",
    "granularity = 2\n",
    "power_level = np.zeros(len(all_summary_LT_ASHP))\n",
    "\n",
    "# Process each property\n",
    "for i, property_id in enumerate(all_summary_LT_ASHP['Property_ID']):\n",
    "    file_path = os.path.join(path_LT_Pulses_Flag, f\"{property_id}.parquet\")\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    # Load household data\n",
    "    household = pd.read_parquet(file_path)\n",
    "\n",
    "    # Convert timestamp to datetime\n",
    "    household['Timestamp'] = pd.to_datetime(household['Timestamp'])\n",
    "\n",
    "    # Extract time-based attributes\n",
    "    household['Year'] = household['Timestamp'].dt.year\n",
    "    household['Month'] = household['Timestamp'].dt.month\n",
    "    household['Day'] = household['Timestamp'].dt.day\n",
    "    household['DayOfYear'] = household['Timestamp'].dt.dayofyear\n",
    "\n",
    "    power_level[i] = household['Heating_Pulses'].max()\n",
    "\n",
    "    # Initialize lists for sparsity and pulses\n",
    "    sparsity_data = []\n",
    "    pulses_data = []\n",
    "\n",
    "    # Process yearly and daily data\n",
    "    for year_iter in range(household['Year'].min(), household['Year'].max() + 1):\n",
    "        household_year = household[household['Year'] == year_iter]\n",
    "\n",
    "        for dayofyear_iter in range(household_year['DayOfYear'].min(), household_year['DayOfYear'].max() + 1):\n",
    "            household_day = household_year[household_year['DayOfYear'] == dayofyear_iter]\n",
    "\n",
    "            timestamp = datetime(year_iter, 1, 1) + timedelta(days=dayofyear_iter - 1)\n",
    "\n",
    "            if household_day.empty:\n",
    "                sparsity_data.append([timestamp, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "                continue\n",
    "\n",
    "            percentage_on = household_day['Heating_Pulse_On'].sum() / len(household_day['Heating_Pulse_On'])\n",
    "            percentage_max_power_on = household_day['Heating_Pulses'].sum() / (\n",
    "                household_day['Heating_Pulse_On'].sum() * power_level[i]\n",
    "            ) if household_day['Heating_Pulse_On'].sum() > 0 else np.nan\n",
    "\n",
    "            # Identify pulse segments\n",
    "            changes = np.diff(household_day['Heating_Pulse_On'].values, prepend=True)\n",
    "            segment_lengths = np.diff(np.where(np.append(changes, True))[0])\n",
    "\n",
    "            counter_pulse = 0\n",
    "            current_point = 0\n",
    "\n",
    "            for seg_length in segment_lengths:\n",
    "                timestamp_pulse = household_day['Timestamp'].iloc[current_point]\n",
    "                on_status = household_day['Heating_Pulse_On'].iloc[current_point]\n",
    "                avg_power = household_day['Heating_Pulses'].iloc[current_point: current_point + seg_length].mean()\n",
    "                energy = avg_power * granularity * seg_length / 60\n",
    "                fullness = avg_power / power_level[i] if power_level[i] != 0 else np.nan\n",
    "\n",
    "                pulses_data.append([timestamp_pulse, granularity * seg_length, on_status, avg_power, energy, fullness])\n",
    "\n",
    "                counter_pulse += 1\n",
    "                current_point += seg_length\n",
    "\n",
    "            pulse_df = pd.DataFrame(pulses_data, columns=['Timestamp', 'Length_Minutes', 'On', 'AveragePower', 'Energy', 'Fullness'])\n",
    "            \n",
    "            # Calculate summary statistics for pulses\n",
    "            on_pulses = pulse_df[pulse_df['On'] == 1]\n",
    "            idle_pulses = pulse_df[pulse_df['On'] == 0]\n",
    "\n",
    "            sparsity_data.append([\n",
    "                timestamp,\n",
    "                percentage_on,\n",
    "                percentage_max_power_on,\n",
    "                len(on_pulses),\n",
    "                len(idle_pulses),\n",
    "                on_pulses['Length_Minutes'].min() if not on_pulses.empty else np.nan,\n",
    "                on_pulses['Length_Minutes'].max() if not on_pulses.empty else np.nan,\n",
    "                on_pulses['Length_Minutes'].mean() if not on_pulses.empty else np.nan,\n",
    "                on_pulses['Length_Minutes'].median() if not on_pulses.empty else np.nan\n",
    "            ])\n",
    "\n",
    "    # Convert to DataFrames\n",
    "    sparsity_df = pd.DataFrame(sparsity_data, columns=[\n",
    "        'Time', 'Percentage_On', 'Percentage_Max_Power_On', 'Number_Of_Pulses', 'Number_Of_Idle',\n",
    "        'Min_Pulse_Duration', 'Max_Pulse_Duration', 'Avg_Pulse_Duration', 'Med_Pulse_Duration'\n",
    "    ])\n",
    "\n",
    "    pulses_df = pd.DataFrame(pulses_data, columns=['Time', 'Length_Minutes', 'On', 'AveragePower', 'Energy', 'Fullness'])\n",
    "\n",
    "    # Save to Parquet\n",
    "    sparsity_output = os.path.join(path_LT_Sparsity, f\"{property_id}.parquet\")\n",
    "    pulses_output = os.path.join(path_LT_Pulses, f\"{property_id}.parquet\")\n",
    "\n",
    "    sparsity_df.to_parquet(sparsity_output, index=False)\n",
    "    pulses_df.to_parquet(pulses_output, index=False)\n",
    "\n",
    "    print(f\"Processed and saved: {sparsity_output}, {pulses_output}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
